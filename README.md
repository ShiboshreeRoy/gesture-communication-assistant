# ğŸ¤– Gesture-Based Communication Assistant

This project is a **Gesture Recognition Communication Assistant** designed to interpret hand gestures in real time using a webcam. It helps individuals, especially those with speech or hearing impairments, to communicate using hand signs. The system leverages **MediaPipe**, **OpenCV**, **PyTTSx3**, and gesture analysis to detect hand gestures and provide real-time audio and visual feedback.

---

## ğŸ“¸ Features

- ğŸ¯ **Real-Time Hand Gesture Recognition**
- ğŸ”Š **Text-to-Speech Output in Multiple Languages** (English, Spanish, French)
- ğŸ§  **Customizable Gesture-to-Message Mapping**
- ğŸ“ **Logs for Communication and Errors**
- ğŸŒ **Dynamic Language Switching Using Gestures**
- ğŸ“· **Live Camera Feed with Gesture Overlays and FPS Counter**

---

## âœ‹ Supported Gestures and Meanings

| Gesture        | Meaning        |
|----------------|----------------|
| ğŸ‘ thumbs_up   | Yes            |
| ğŸ‘ thumbs_down | No             |
| âœŠ fist         | Stop           |
| ğŸ– palm_together| Hello         |
| â˜ one          | One            |
| âœŒ two          | Two / Switch Language |
| ğŸ¤Ÿ iloveyou     | I love you     |
| ğŸ‘Œ ok           | Okay           |
| ğŸ¤™ shaka        | Call me        |
| ğŸ–âœŒâœŒâœŒ four fingers | Four         |
| ğŸ–âœŒâœŒâœŒâœŒ five fingers | Palm        |

---

## ğŸ§© Technologies Used

- [Python 3.x](https://www.python.org/)
- [MediaPipe](https://google.github.io/mediapipe/) â€“ for hand landmark detection
- [OpenCV](https://opencv.org/) â€“ for image processing and camera feed
- [PyTTSx3](https://pyttsx3.readthedocs.io/) â€“ for offline text-to-speech
- [NumPy](https://numpy.org/) â€“ for numerical analysis
- [JSON](https://www.json.org/) â€“ for configuration

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/shiboshreeroy/gesture-communication-assistant.git
cd gesture-communication-assistant
````

### 2. Install dependencies

```bash
pip install opencv-python mediapipe pyttsx3 numpy
```

> **Note:** On Linux systems, you may also need `espeak` or `libespeak1` for text-to-speech to work.

### 3. Run the application

```bash
python main.py
```

---

## ğŸ—‚ Project Structure

```
gesture-communication-assistant/
â”‚
â”œâ”€â”€ main.py                   # Entry point
â”œâ”€â”€ gestures.json             # Custom gesture-message mappings
â”œâ”€â”€ error_log.txt             # Runtime error logs
â”œâ”€â”€ communication_log.txt     # Timestamped communication logs
â””â”€â”€ README.md                 # Project overview
```

---

## ğŸ›  Customization

You can customize gestures and their associated messages in the `gestures.json` file:

```json
{
    "thumbs_up": "Yes",
    "thumbs_down": "No",
    "two": "Change Language"
}
```

---

## ğŸš€ Future Improvements

* Add GUI support with Tkinter or PyQt
* Add gesture training and user-specific calibration
* Export communication logs to PDF
* Add voice command fallback

---

## ğŸ‘¨â€ğŸ’» Author

**Shiboshree Roy**
Full Stack Developer & Open Source Contributor
[GitHub](https://github.com/shiboshree-roy) â€¢ [LinkedIn](https://www.linkedin.com/in/shiboshree-roy)

---

## ğŸ“œ License

This project is open source under the [MIT License](LICENSE).


